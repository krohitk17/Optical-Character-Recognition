{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CONTOUR_AREA = 80                       # minimum area of valid contour\n",
    "MAX_CONTOUR_AREA = 1200                     # maximum area of valid contour\n",
    "\n",
    "RESIZED_IMAGE_WIDTH = 20                    # width of resized image\n",
    "RESIZED_IMAGE_HEIGHT = 30                   # height of resized image\n",
    "\n",
    "TRAINING_IMAGES_PATH = 'train_images'                                       # folder with training images\n",
    "TESTING_IMAGES_PATH = 'test_images'                                         # folder with testing images\n",
    "TRAINING_ALPHA = TRAINING_IMAGES_PATH + '/' + \"train_alpha2.png\"            # training alphabet image\n",
    "TRAINING_DIGIT = TRAINING_IMAGES_PATH + '/' + \"train_digit2.png\"            # training digit image\n",
    "TEST_IMAGE = TESTING_IMAGES_PATH + '/' + \"test4.png\"                        # test image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define contour class to store characters in test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContourWithData():\n",
    "    npaContour = None           # contour\n",
    "    boundingRect = None         # bounding rect for contour\n",
    "    intRectX = 0                # bounding rect top left corner x location\n",
    "    intRectY = 0                # bounding rect top left corner y location\n",
    "    intRectWidth = 0            # bounding rect width\n",
    "    intRectHeight = 0           # bounding rect height\n",
    "    fltArea = 0.0               # area of contour\n",
    "\n",
    "    # calculate bounding rect info\n",
    "    def calculateRectTopLeftPointAndWidthAndHeight(self):\n",
    "        [intX, intY, intWidth, intHeight] = self.boundingRect\n",
    "        self.intRectX = intX\n",
    "        self.intRectY = intY\n",
    "        self.intRectWidth = intWidth\n",
    "        self.intRectHeight = intHeight\n",
    "\n",
    "    # this is oversimplified, for a production grade program\n",
    "    def checkIfContourIsValid(self):\n",
    "        if self.fltArea < MIN_CONTOUR_AREA or self.fltArea > MAX_CONTOUR_AREA: \n",
    "            return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open training characters image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgTrainingAlpha = cv2.imread(TRAINING_ALPHA)               # read in training alpha image\n",
    "imgTrainingDigit = cv2.imread(TRAINING_DIGIT)               # read in training digit image\n",
    "\n",
    "if imgTrainingAlpha is None:                                # if image was not read successfully\n",
    "    # print error message to std out\n",
    "    print(\"error: alpha image not read from file \\n\\n\")\n",
    "    # and exit function (which exits program)\n",
    "    exit()\n",
    "# end if\n",
    "if imgTrainingDigit is None:                                # if image was not read successfully\n",
    "    # print error message to std out\n",
    "    print(\"error: digit image not read from file \\n\\n\")\n",
    "    # and exit function (which exits program)\n",
    "    exit()\n",
    "# end if"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify training alphabet image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgGrayAlpha = cv2.cvtColor(imgTrainingAlpha, cv2.COLOR_BGR2GRAY)               # get grayscale image\n",
    "imgBlurredAlpha = cv2.GaussianBlur(imgGrayAlpha, (5, 5), 0)                     # blur\n",
    "\n",
    "# filter image from grayscale to black and white\n",
    "imgThreshAlpha = cv2.adaptiveThreshold( imgBlurredAlpha,\n",
    "                                        # make pixels that pass the threshold full white\n",
    "                                        255,                                  \n",
    "                                        # use gaussian rather than mean, seems to give better results\n",
    "                                        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                        # invert so foreground will be white, background will be black\n",
    "                                        cv2.THRESH_BINARY_INV,\n",
    "                                        # size of a pixel neighborhood used to calculate threshold value\n",
    "                                        11,\n",
    "                                        # constant subtracted from the mean or weighted mean\n",
    "                                        2)                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find seperate characters from alphabet image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "npaContoursAlpha, _ = cv2.findContours(# input image, use a copy since the function will modify this image in the course of finding contours\n",
    "                                       imgThreshAlpha.copy(),\n",
    "                                       # retrieve the outermost contours only\n",
    "                                       cv2.RETR_EXTERNAL,\n",
    "                                       # compress horizontal, vertical, and diagonal segments and leave only their end points\n",
    "                                       cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify training digit image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgGrayDigit = cv2.cvtColor(imgTrainingDigit, cv2.COLOR_BGR2GRAY)                   # get grayscale image\n",
    "imgBlurredDigit = cv2.GaussianBlur(imgGrayDigit, (5, 5), 0)                         # blur\n",
    "\n",
    "# filter image from grayscale to black and white\n",
    "imgThreshDigit = cv2.adaptiveThreshold(imgBlurredDigit,                             # input image\n",
    "                                        # make pixels that pass the threshold full white\n",
    "                                        255,\n",
    "                                        # use gaussian rather than mean, seems to give better results\n",
    "                                        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                        # invert so foreground will be white, background will be black\n",
    "                                        cv2.THRESH_BINARY_INV,\n",
    "                                        # size of a pixel neighborhood used to calculate threshold value\n",
    "                                        11,\n",
    "                                        # constant subtracted from the mean or weighted mean\n",
    "                                        2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find separate characters from digit image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "npaContoursDigit, _ = cv2.findContours(imgThreshDigit.copy(),       # input image, make sure to use a copy since the function will modify this image in the course of finding contours\n",
    "                                       cv2.RETR_EXTERNAL,           # retrieve the outermost contours only\n",
    "                                       cv2.CHAIN_APPROX_SIMPLE)     # compress horizontal, vertical, and diagonal segments and leave only their end points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare empty arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AlphaContours = []\n",
    "DigitContours = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create objects for alphabet contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for npaContour in npaContoursAlpha:                                 # for each contour\n",
    "    # instantiate a contour with data object\n",
    "    contourWithData = ContourWithData()\n",
    "    # assign contour to contour with data\n",
    "    contourWithData.npaContour = npaContour\n",
    "    # get the bounding rect\n",
    "    contourWithData.boundingRect = cv2.boundingRect(contourWithData.npaContour)\n",
    "    # get bounding rect info\n",
    "    contourWithData.calculateRectTopLeftPointAndWidthAndHeight()\n",
    "    # calculate the contour area\n",
    "    contourWithData.fltArea = cv2.contourArea(contourWithData.npaContour)\n",
    "    # add contour with data object to list of all contours with data\n",
    "    if contourWithData.checkIfContourIsValid():\n",
    "        AlphaContours.append(contourWithData)\n",
    "    # end if\n",
    "# end for\n",
    "\n",
    "# sort contours from left to right\n",
    "AlphaContours.sort(key = lambda x: [x.intRectX, x.intRectY // x.intRectHeight])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create objects for digit contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for npaContour in npaContoursDigit:                                 # for each contour\n",
    "    # instantiate a contour with data object\n",
    "    contourWithData = ContourWithData()\n",
    "    # assign contour to contour with data\n",
    "    contourWithData.npaContour = npaContour\n",
    "    # get the bounding rect\n",
    "    contourWithData.boundingRect = cv2.boundingRect(contourWithData.npaContour)\n",
    "    # get bounding rect info\n",
    "    contourWithData.calculateRectTopLeftPointAndWidthAndHeight()\n",
    "    # calculate the contour area\n",
    "    contourWithData.fltArea = cv2.contourArea(contourWithData.npaContour)\n",
    "    # add contour with data object to list of all contours with data\n",
    "    if contourWithData.checkIfContourIsValid():\n",
    "        DigitContours.append(contourWithData)\n",
    "    # end if\n",
    "# end for\n",
    "\n",
    "# sort contours from left to right\n",
    "DigitContours.sort(key=lambda x: x.intRectX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create empty arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "npaFlattenedImages = np.empty((0, RESIZED_IMAGE_WIDTH * RESIZED_IMAGE_HEIGHT))\n",
    "\n",
    "# declare empty classifications list, this will be our list of how we are classifying our chars from user input, we will write to file at the end\n",
    "intClassifications = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label alphabet images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 28\n",
      "A 27\n",
      "A 26\n",
      "A 27\n",
      "A 24\n",
      "B 31\n",
      "B 29\n",
      "B 34\n",
      "B 27\n",
      "B 31\n",
      "C 35\n",
      "C 36\n",
      "C 38\n",
      "C 30\n",
      "C 29\n",
      "D 47\n",
      "D 42\n",
      "D 45\n",
      "D 37\n",
      "D 43\n",
      "E 28\n",
      "E 30\n",
      "E 31\n",
      "E 23\n",
      "E 29\n",
      "F 29\n",
      "F 27\n",
      "F 24\n",
      "F 27\n",
      "F 21\n",
      "G 29\n",
      "G 32\n",
      "G 33\n",
      "G 30\n",
      "G 31\n",
      "H 30\n",
      "H 32\n",
      "H 29\n",
      "H 26\n",
      "H 25\n",
      "I 39\n",
      "I 43\n",
      "I 48\n",
      "I 40\n",
      "I 39\n",
      "J 30\n",
      "J 38\n",
      "J 32\n",
      "J 29\n",
      "J 26\n",
      "K 36\n",
      "K 36\n",
      "K 33\n",
      "K 28\n",
      "K 31\n",
      "L 31\n",
      "L 28\n",
      "L 28\n",
      "L 25\n",
      "L 22\n",
      "M 30\n",
      "M 29\n",
      "M 36\n",
      "M 31\n",
      "M 32\n",
      "N 32\n",
      "N 36\n",
      "N 32\n",
      "N 36\n",
      "N 31\n",
      "O 36\n",
      "O 28\n",
      "O 24\n",
      "O 25\n",
      "O 30\n",
      "P 21\n",
      "P 27\n",
      "P 24\n",
      "P 21\n",
      "P 24\n",
      "Q 42\n",
      "Q 37\n",
      "Q 37\n",
      "Q 33\n",
      "Q 39\n",
      "R 31\n",
      "R 35\n",
      "R 29\n",
      "R 33\n",
      "R 27\n",
      "S 29\n",
      "S 25\n",
      "S 25\n",
      "S 26\n",
      "S 23\n",
      "T 36\n",
      "T 41\n",
      "T 33\n",
      "T 37\n",
      "T 36\n",
      "U 30\n",
      "U 27\n",
      "U 23\n",
      "U 31\n",
      "U 29\n",
      "V 37\n",
      "V 34\n",
      "V 35\n",
      "V 33\n",
      "V 30\n",
      "W 44\n",
      "W 42\n",
      "W 39\n",
      "W 42\n",
      "W 35\n",
      "X 38\n",
      "X 29\n",
      "X 30\n",
      "X 35\n",
      "X 29\n",
      "Y 28\n",
      "Y 35\n",
      "Y 31\n",
      "Y 33\n",
      "Y 29\n",
      "Z 48\n",
      "Z 42\n",
      "Z 45\n",
      "Z 46\n",
      "Z 45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char = 65\n",
    "for i in range(len(AlphaContours)):                         # for each contour\n",
    "    npaContour = AlphaContours[i]\n",
    "    #increment character if new column\n",
    "    if npaContour.intRectX - AlphaContours[i-1].intRectX >= AlphaContours[i-1].intRectWidth:\n",
    "        char += 1\n",
    "    # crop char out of threshold image\n",
    "    imgROI = imgThreshAlpha[npaContour.intRectY: npaContour.intRectY + npaContour.intRectHeight,\n",
    "                            npaContour.intRectX: npaContour.intRectX + npaContour.intRectWidth]\n",
    "    # resize image, this will be more consistent for recognition and storage\n",
    "    imgROIResized = cv2.resize(imgROI, (RESIZED_IMAGE_WIDTH, RESIZED_IMAGE_HEIGHT))\n",
    "    # show training numbers image\n",
    "    intClassifications.append(char)\n",
    "    # flatten image to 1d numpy array so we can write to file later\n",
    "    npaFlattenedImage = imgROIResized.reshape((1, RESIZED_IMAGE_WIDTH * RESIZED_IMAGE_HEIGHT))\n",
    "    # add current flattened impage numpy array to list of flattened image numpy arrays\n",
    "    npaFlattenedImages = np.append(npaFlattenedImages, npaFlattenedImage, 0)\n",
    "    # get bounding rectangle\n",
    "    cv2.rectangle(imgTrainingAlpha, (npaContour.intRectX, npaContour.intRectY),\n",
    "                    (npaContour.intRectX + npaContour.intRectWidth, npaContour.intRectY + npaContour.intRectHeight),\n",
    "                    (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Training Alphabets\", imgTrainingAlpha)\n",
    "    print(chr(char), npaContour.intRectWidth)\n",
    "    cv2.waitKey(500)\n",
    "# end for\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label digit images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 26\n",
      "0 30\n",
      "0 26\n",
      "0 30\n",
      "0 36\n",
      "1 10\n",
      "1 10\n",
      "1 7\n",
      "1 10\n",
      "1 9\n",
      "2 34\n",
      "2 39\n",
      "2 31\n",
      "2 26\n",
      "2 28\n",
      "3 21\n",
      "3 26\n",
      "3 26\n",
      "3 26\n",
      "3 23\n",
      "4 29\n",
      "4 23\n",
      "4 25\n",
      "4 27\n",
      "4 24\n",
      "5 25\n",
      "5 29\n",
      "5 24\n",
      "5 24\n",
      "5 25\n",
      "6 20\n",
      "6 19\n",
      "6 21\n",
      "6 19\n",
      "6 19\n",
      "7 29\n",
      "7 19\n",
      "7 27\n",
      "7 19\n",
      "7 21\n",
      "8 20\n",
      "8 21\n",
      "8 24\n",
      "8 23\n",
      "8 23\n",
      "9 21\n",
      "9 22\n",
      "9 25\n",
      "9 26\n",
      "9 24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char = 48\n",
    "for i in range(len(DigitContours)):                      # for each contour\n",
    "    npaContour = DigitContours[i]\n",
    "    #increment character if new column\n",
    "    if npaContour.intRectX - DigitContours[i-1].intRectX >= DigitContours[i-1].intRectWidth:\n",
    "        char += 1\n",
    "    # crop char out of threshold image\n",
    "    imgROI = imgThreshDigit[npaContour.intRectY: npaContour.intRectY + npaContour.intRectHeight,\n",
    "                            npaContour.intRectX: npaContour.intRectX + npaContour.intRectWidth]\n",
    "    # resize image, this will be more consistent for recognition and storage\n",
    "    imgROIResized = cv2.resize(imgROI, (RESIZED_IMAGE_WIDTH, RESIZED_IMAGE_HEIGHT))\n",
    "    # show training numbers image\n",
    "    intClassifications.append(char)\n",
    "    # flatten image to 1d numpy array so we can write to file later\n",
    "    npaFlattenedImage = imgROIResized.reshape((1, RESIZED_IMAGE_WIDTH * RESIZED_IMAGE_HEIGHT))\n",
    "    # add current flattened impage numpy array to list of flattened image numpy arrays\n",
    "    npaFlattenedImages = np.append(npaFlattenedImages, npaFlattenedImage, 0)\n",
    "    # get bounding rectangle\n",
    "    cv2.rectangle(imgTrainingDigit, (npaContour.intRectX, npaContour.intRectY),\n",
    "                  (npaContour.intRectX + npaContour.intRectWidth,\n",
    "                   npaContour.intRectY + npaContour.intRectHeight),\n",
    "                  (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Training Digits\", imgTrainingDigit)\n",
    "    print(chr(char), npaContour.intRectWidth)\n",
    "    cv2.waitKey(500)\n",
    "# end for\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "training complete !!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fltClassifications = np.array(intClassifications, np.float32)\n",
    "\n",
    "# flatten numpy array of floats to 1d so we can write to file later\n",
    "npaClassifications = fltClassifications.reshape((fltClassifications.size, 1))\n",
    "\n",
    "print(\"\\n\\ntraining complete !!\\n\")\n",
    "\n",
    "# write flattened images to file\n",
    "np.savetxt(\"classifications.txt\", npaClassifications)\n",
    "np.savetxt(\"flattened_images.txt\", npaFlattenedImages)\n",
    "\n",
    "# remove windows from memory\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open classifications and flattened_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in training classifications\n",
    "try:\n",
    "    npaClassifications = np.loadtxt(\"classifications.txt\", np.float32)\n",
    "except:\n",
    "    print(\"error, unable to open classifications.txt, exiting program\\n\")\n",
    "    exit()\n",
    "# end try\n",
    "\n",
    "# read in training images\n",
    "try:\n",
    "    npaFlattenedImages = np.loadtxt(\"flattened_images.txt\", np.float32)\n",
    "except:\n",
    "    print(\"error, unable to open flattened_images.txt, exiting program\\n\")\n",
    "    exit()\n",
    "# end try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape numpy array to 1d, necessary to pass to call to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "npaClassifications = npaClassifications.reshape((npaClassifications.size, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create KNN object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kNearest = cv2.ml.KNearest_create()         # instantiate KNN object\n",
    "kNearest.train(npaFlattenedImages, cv2.ml.ROW_SAMPLE, npaClassifications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open testing image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(TEST_IMAGE)                # read in testing image\n",
    "if img is None:                             # if image was not read successfully\n",
    "    print(\"error: image not read from file \\n\\n\")\n",
    "    exit()\n",
    "# end if"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get grayscale image\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# blur image to reduce noise\n",
    "imgBlurred = cv2.GaussianBlur(imgGray, (5, 5), 0)                    \n",
    "# filter image from grayscale to black and white\n",
    "imgThresh = cv2.adaptiveThreshold(imgBlurred,                       # input image\n",
    "                                  255,                              # make pixels that pass the threshold full white\n",
    "                                  cv2.ADAPTIVE_THRESH_GAUSSIAN_C,   # use gaussian rather than mean, seems to give better results\n",
    "                                  cv2.THRESH_BINARY_INV,            # invert so foreground will be white, background will be black\n",
    "                                  11,                               # size of a pixel neighborhood used to calculate threshold value\n",
    "                                  2)                                # constant subtracted from the mean or weighted mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get separate contours from testing image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "npaContours, npaHierarchy = cv2.findContours(# input image copy since the function will modify this image in the course of finding contours\n",
    "                                             imgThresh.copy(),          \n",
    "                                             # retrieve the outermost contours only\n",
    "                                             cv2.RETR_EXTERNAL,         \n",
    "                                             # compress horizontal, vertical, and diagonal segments and leave only their end points\n",
    "                                             cv2.CHAIN_APPROX_SIMPLE)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create empty array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "allContoursWithData = []                # store all valid contours in testing image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create objects for each contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for npaContour in npaContours:          # for each contour\n",
    "    # instantiate a contour with data object\n",
    "    contourWithData = ContourWithData()\n",
    "    # assign contour to contour with data\n",
    "    contourWithData.npaContour = npaContour\n",
    "    # get the bounding rect\n",
    "    contourWithData.boundingRect = cv2.boundingRect(contourWithData.npaContour)     \n",
    "    # get bounding rect info\n",
    "    contourWithData.calculateRectTopLeftPointAndWidthAndHeight()                    \n",
    "    # calculate the contour area\n",
    "    contourWithData.fltArea = cv2.contourArea(contourWithData.npaContour)\n",
    "    # add contour with data object to list of all contours with data\n",
    "    if contourWithData.checkIfContourIsValid():\n",
    "        allContoursWithData.append(contourWithData)\n",
    "# end for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort contours from left to right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find maximum height of all contours\n",
    "maxHeight = max(allContoursWithData, key=lambda x: x.intRectHeight).intRectHeight\n",
    "# sort contours from left to right\n",
    "allContoursWithData.sort(key=lambda x: [x.intRectY // maxHeight, x.intRectX])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare final string, this will have the final number sequence by the end of the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "strFinalString = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T\n",
      "E\n",
      "S\n",
      "T\n",
      "T\n",
      "H\n",
      "I\n",
      "S\n",
      "I\n",
      "M\n",
      "A\n",
      "G\n",
      "E\n",
      "5\n",
      "9\n",
      "8\n",
      "O\n",
      "4\n",
      "6\n",
      "E\n",
      "\n",
      "TESTTHISIMAGE598O46E\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(allContoursWithData)):            # for each contour\n",
    "    # draw rectangle on original testing image\n",
    "    contourWithData = allContoursWithData[i]\n",
    "    cv2.rectangle(img,                                        \n",
    "                  # upper left corner\n",
    "                  (contourWithData.intRectX, contourWithData.intRectY),\n",
    "                  (contourWithData.intRectX + contourWithData.intRectWidth,\n",
    "                   contourWithData.intRectY + contourWithData.intRectHeight),       # lower right corner\n",
    "                  (0, 255, 0),                                                      # green\n",
    "                  2)                                                                # thickness\n",
    "\n",
    "    # crop char out of threshold image\n",
    "    imgROI = imgThresh[contourWithData.intRectY: contourWithData.intRectY + contourWithData.intRectHeight,     \n",
    "                       contourWithData.intRectX: contourWithData.intRectX + contourWithData.intRectWidth]\n",
    "\n",
    "    # resize image, this will be more consistent for recognition and storage\n",
    "    imgROIResized = cv2.resize(imgROI, (RESIZED_IMAGE_WIDTH, RESIZED_IMAGE_HEIGHT))\n",
    "\n",
    "    # flatten image into 1d numpy array\n",
    "    npaROIResized = imgROIResized.reshape((1, RESIZED_IMAGE_WIDTH * RESIZED_IMAGE_HEIGHT))\n",
    "\n",
    "    # convert from 1d numpy array of ints to 1d numpy array of floats\n",
    "    npaROIResized = np.float32(npaROIResized)\n",
    "\n",
    "    # call KNN function find_nearest\n",
    "    retval, npaResults, neigh_resp, dists = kNearest.findNearest(npaROIResized, k=1)\n",
    "    \n",
    "    # get character from results\n",
    "    strCurrentChar = str(chr(int(npaResults[0][0])))\n",
    "\n",
    "    cv2.imshow(\"Test Image\", img)\n",
    "    print(strCurrentChar)\n",
    "    if cv2.waitKey(500) == 27:\n",
    "        exit()\n",
    "    \n",
    "    # check new line\n",
    "    if contourWithData.intRectY  > allContoursWithData[i - 1].intRectY + contourWithData.intRectHeight:\n",
    "        strFinalString += '\\n'\n",
    "    # end if\n",
    "    \n",
    "    # append current char to full string\n",
    "    strFinalString = strFinalString + strCurrentChar\n",
    "# end for\n",
    "\n",
    "print(\"\\n\" + strFinalString + \"\\n\")             # show final string\n",
    "cv2.destroyAllWindows()                         # remove windows from memory\n",
    "cv2.waitKey(5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0537185041308504c74fc460ad6cbac8f2acb86b816e1703bfbad8fd9b716429"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('OCR-pYR5qIn7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
