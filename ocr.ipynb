{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CONTOUR_AREA = 80                       # minimum area of valid contour\n",
    "MAX_CONTOUR_AREA = 1200                     # maximum area of valid contour\n",
    "\n",
    "RESIZED_IMAGE_WIDTH = 20                    # width of resized image\n",
    "RESIZED_IMAGE_HEIGHT = 30                   # height of resized image\n",
    "\n",
    "TRAINING_IMAGES_PATH = 'train_images'                                       # folder with training images\n",
    "TESTING_IMAGES_PATH = 'test_images'                                         # folder with testing images\n",
    "TRAINING_ALPHA = TRAINING_IMAGES_PATH + '/' + \"train_alpha2.png\"            # training alphabet image\n",
    "TRAINING_DIGIT = TRAINING_IMAGES_PATH + '/' + \"train_digit2.png\"            # training digit image\n",
    "TEST_IMAGE = TESTING_IMAGES_PATH + '/' + \"test1.png\"                        # test image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define contour class to store characters in test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContourWithData():\n",
    "    npaContour = None           # contour\n",
    "    boundingRect = None         # bounding rect for contour\n",
    "    intRectX = 0                # bounding rect top left corner x location\n",
    "    intRectY = 0                # bounding rect top left corner y location\n",
    "    intRectWidth = 0            # bounding rect width\n",
    "    intRectHeight = 0           # bounding rect height\n",
    "    fltArea = 0.0               # area of contour\n",
    "\n",
    "    # calculate bounding rect info\n",
    "    def calculateRectTopLeftPointAndWidthAndHeight(self):\n",
    "        [intX, intY, intWidth, intHeight] = self.boundingRect\n",
    "        self.intRectX = intX\n",
    "        self.intRectY = intY\n",
    "        self.intRectWidth = intWidth\n",
    "        self.intRectHeight = intHeight\n",
    "\n",
    "    # this is oversimplified, for a production grade program\n",
    "    def checkIfContourIsValid(self):\n",
    "        if self.fltArea < MIN_CONTOUR_AREA or self.fltArea > MAX_CONTOUR_AREA: \n",
    "            return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open training characters image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgTrainingAlpha = cv2.imread(TRAINING_ALPHA)               # read in training alpha image\n",
    "imgTrainingDigit = cv2.imread(TRAINING_DIGIT)               # read in training digit image\n",
    "\n",
    "if imgTrainingAlpha is None:                                # if image was not read successfully\n",
    "    # print error message to std out\n",
    "    print(\"error: alpha image not read from file \\n\\n\")\n",
    "    # and exit function (which exits program)\n",
    "    exit(0)\n",
    "# end if\n",
    "if imgTrainingDigit is None:                                # if image was not read successfully\n",
    "    # print error message to std out\n",
    "    print(\"error: digit image not read from file \\n\\n\")\n",
    "    # and exit function (which exits program)\n",
    "    exit(0)\n",
    "# end if"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify training alphabet image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgGrayAlpha = cv2.cvtColor(imgTrainingAlpha, cv2.COLOR_BGR2GRAY)               # get grayscale image\n",
    "imgBlurredAlpha = cv2.GaussianBlur(imgGrayAlpha, (5, 5), 0)                     # blur\n",
    "\n",
    "# filter image from grayscale to black and white\n",
    "imgThreshAlpha = cv2.adaptiveThreshold( imgBlurredAlpha,\n",
    "                                        # make pixels that pass the threshold full white\n",
    "                                        255,                                  \n",
    "                                        # use gaussian rather than mean, seems to give better results\n",
    "                                        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                        # invert so foreground will be white, background will be black\n",
    "                                        cv2.THRESH_BINARY_INV,\n",
    "                                        # size of a pixel neighborhood used to calculate threshold value\n",
    "                                        11,\n",
    "                                        # constant subtracted from the mean or weighted mean\n",
    "                                        2)                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find seperate characters from alphabet image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npaContoursAlpha, _ = cv2.findContours(# input image, use a copy since the function will modify this image in the course of finding contours\n",
    "                                       imgThreshAlpha.copy(),\n",
    "                                       # retrieve the outermost contours only\n",
    "                                       cv2.RETR_EXTERNAL,\n",
    "                                       # compress horizontal, vertical, and diagonal segments and leave only their end points\n",
    "                                       cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify training digit image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgGrayDigit = cv2.cvtColor(imgTrainingDigit, cv2.COLOR_BGR2GRAY)                   # get grayscale image\n",
    "imgBlurredDigit = cv2.GaussianBlur(imgGrayDigit, (5, 5), 0)                         # blur\n",
    "\n",
    "# filter image from grayscale to black and white\n",
    "imgThreshDigit = cv2.adaptiveThreshold(imgBlurredDigit,                             # input image\n",
    "                                        # make pixels that pass the threshold full white\n",
    "                                        255,\n",
    "                                        # use gaussian rather than mean, seems to give better results\n",
    "                                        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                        # invert so foreground will be white, background will be black\n",
    "                                        cv2.THRESH_BINARY_INV,\n",
    "                                        # size of a pixel neighborhood used to calculate threshold value\n",
    "                                        11,\n",
    "                                        # constant subtracted from the mean or weighted mean\n",
    "                                        2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find separate characters from digit image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npaContoursDigit, _ = cv2.findContours(imgThreshDigit.copy(),       # input image, make sure to use a copy since the function will modify this image in the course of finding contours\n",
    "                                       cv2.RETR_EXTERNAL,           # retrieve the outermost contours only\n",
    "                                       cv2.CHAIN_APPROX_SIMPLE)     # compress horizontal, vertical, and diagonal segments and leave only their end points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare empty arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AlphaContours = []\n",
    "DigitContours = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create objects for alphabet contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for npaContour in npaContoursAlpha:                                 # for each contour\n",
    "    # instantiate a contour with data object\n",
    "    contourWithData = ContourWithData()\n",
    "    # assign contour to contour with data\n",
    "    contourWithData.npaContour = npaContour\n",
    "    # get the bounding rect\n",
    "    contourWithData.boundingRect = cv2.boundingRect(contourWithData.npaContour)\n",
    "    # get bounding rect info\n",
    "    contourWithData.calculateRectTopLeftPointAndWidthAndHeight()\n",
    "    # calculate the contour area\n",
    "    contourWithData.fltArea = cv2.contourArea(contourWithData.npaContour)\n",
    "    # add contour with data object to list of all contours with data\n",
    "    if contourWithData.checkIfContourIsValid():\n",
    "        AlphaContours.append(contourWithData)\n",
    "    # end if\n",
    "# end for\n",
    "\n",
    "# sort contours from left to right\n",
    "AlphaContours.sort(key = lambda x: x.intRectX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create objects for digit contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for npaContour in npaContoursDigit:                                 # for each contour\n",
    "    # instantiate a contour with data object\n",
    "    contourWithData = ContourWithData()\n",
    "    # assign contour to contour with data\n",
    "    contourWithData.npaContour = npaContour\n",
    "    # get the bounding rect\n",
    "    contourWithData.boundingRect = cv2.boundingRect(contourWithData.npaContour)\n",
    "    # get bounding rect info\n",
    "    contourWithData.calculateRectTopLeftPointAndWidthAndHeight()\n",
    "    # calculate the contour area\n",
    "    contourWithData.fltArea = cv2.contourArea(contourWithData.npaContour)\n",
    "    # add contour with data object to list of all contours with data\n",
    "    if contourWithData.checkIfContourIsValid():\n",
    "        DigitContours.append(contourWithData)\n",
    "    # end if\n",
    "# end for\n",
    "\n",
    "# sort contours from left to right\n",
    "DigitContours.sort(key=lambda x: x.intRectX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create empty arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npaFlattenedImages = np.empty((0, RESIZED_IMAGE_WIDTH * RESIZED_IMAGE_HEIGHT))\n",
    "\n",
    "# declare empty classifications list, this will be our list of how we are classifying our chars from user input, we will write to file at the end\n",
    "intClassifications = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label alphabet images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char = 65\n",
    "for i in range(len(AlphaContours)):                         # for each contour\n",
    "    npaContour = AlphaContours[i]\n",
    "    #increment character if new column\n",
    "    if npaContour.intRectX - AlphaContours[i-1].intRectX >= AlphaContours[i-1].intRectWidth:\n",
    "        char += 1\n",
    "    # crop char out of threshold image\n",
    "    imgROI = imgThreshAlpha[npaContour.intRectY: npaContour.intRectY + npaContour.intRectHeight,\n",
    "                            npaContour.intRectX: npaContour.intRectX + npaContour.intRectWidth]\n",
    "    # resize image, this will be more consistent for recognition and storage\n",
    "    imgROIResized = cv2.resize(imgROI, (RESIZED_IMAGE_WIDTH, RESIZED_IMAGE_HEIGHT))\n",
    "    # show training numbers image\n",
    "    intClassifications.append(char)\n",
    "    # flatten image to 1d numpy array so we can write to file later\n",
    "    npaFlattenedImage = imgROIResized.reshape((1, RESIZED_IMAGE_WIDTH * RESIZED_IMAGE_HEIGHT))\n",
    "    # add current flattened impage numpy array to list of flattened image numpy arrays\n",
    "    npaFlattenedImages = np.append(npaFlattenedImages, npaFlattenedImage, 0)\n",
    "    # get bounding rectangle\n",
    "    cv2.rectangle(imgTrainingAlpha, (npaContour.intRectX, npaContour.intRectY),\n",
    "                    (npaContour.intRectX + npaContour.intRectWidth, npaContour.intRectY + npaContour.intRectHeight),\n",
    "                    (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Training Alphabets\", imgTrainingAlpha)\n",
    "    print(chr(char), npaContour.intRectWidth)\n",
    "    cv2.waitKey(500)\n",
    "# end for\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label digit images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char = 48\n",
    "for i in range(len(DigitContours)):                      # for each contour\n",
    "    npaContour = DigitContours[i]\n",
    "    #increment character if new column\n",
    "    if npaContour.intRectX - DigitContours[i-1].intRectX >= DigitContours[i-1].intRectWidth:\n",
    "        char += 1\n",
    "    # crop char out of threshold image\n",
    "    imgROI = imgThreshDigit[npaContour.intRectY: npaContour.intRectY + npaContour.intRectHeight,\n",
    "                            npaContour.intRectX: npaContour.intRectX + npaContour.intRectWidth]\n",
    "    # resize image, this will be more consistent for recognition and storage\n",
    "    imgROIResized = cv2.resize(imgROI, (RESIZED_IMAGE_WIDTH, RESIZED_IMAGE_HEIGHT))\n",
    "    # show training numbers image\n",
    "    intClassifications.append(char)\n",
    "    # flatten image to 1d numpy array so we can write to file later\n",
    "    npaFlattenedImage = imgROIResized.reshape((1, RESIZED_IMAGE_WIDTH * RESIZED_IMAGE_HEIGHT))\n",
    "    # add current flattened impage numpy array to list of flattened image numpy arrays\n",
    "    npaFlattenedImages = np.append(npaFlattenedImages, npaFlattenedImage, 0)\n",
    "    # get bounding rectangle\n",
    "    cv2.rectangle(imgTrainingDigit, (npaContour.intRectX, npaContour.intRectY),\n",
    "                  (npaContour.intRectX + npaContour.intRectWidth,\n",
    "                   npaContour.intRectY + npaContour.intRectHeight),\n",
    "                  (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Training Digits\", imgTrainingDigit)\n",
    "    print(chr(char), npaContour.intRectWidth)\n",
    "# end for\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fltClassifications = np.array(intClassifications, np.float32)\n",
    "\n",
    "# flatten numpy array of floats to 1d so we can write to file later\n",
    "npaClassifications = fltClassifications.reshape((fltClassifications.size, 1))\n",
    "\n",
    "print(\"\\n\\ntraining complete !!\\n\")\n",
    "\n",
    "# write flattened images to file\n",
    "np.savetxt(\"classifications.txt\", npaClassifications)\n",
    "np.savetxt(\"flattened_images.txt\", npaFlattenedImages)\n",
    "\n",
    "# remove windows from memory\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open classifications and flattened_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in training classifications\n",
    "try:\n",
    "    npaClassifications = np.loadtxt(\"classifications.txt\", np.float32)\n",
    "except:\n",
    "    print(\"error, unable to open classifications.txt, exiting program\\n\")\n",
    "    exit(0)\n",
    "# end try\n",
    "\n",
    "# read in training images\n",
    "try:\n",
    "    npaFlattenedImages = np.loadtxt(\"flattened_images.txt\", np.float32)\n",
    "except:\n",
    "    print(\"error, unable to open flattened_images.txt, exiting program\\n\")\n",
    "    exit(0)\n",
    "# end try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape numpy array to 1d, necessary to pass to call to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "npaClassifications = npaClassifications.reshape((npaClassifications.size, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create KNN object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kNearest = cv2.ml.KNearest_create()         # instantiate KNN object\n",
    "kNearest.train(npaFlattenedImages, cv2.ml.ROW_SAMPLE, npaClassifications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open testing image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(TEST_IMAGE)                # read in testing image\n",
    "if img is None:                             # if image was not read successfully\n",
    "    print(\"error: image not read from file \\n\\n\")\n",
    "    exit(0)\n",
    "# end if"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get grayscale image\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# blur image to reduce noise\n",
    "imgBlurred = cv2.GaussianBlur(imgGray, (5, 5), 0)                    \n",
    "# filter image from grayscale to black and white\n",
    "imgThresh = cv2.adaptiveThreshold(imgBlurred,                       # input image\n",
    "                                  255,                              # make pixels that pass the threshold full white\n",
    "                                  cv2.ADAPTIVE_THRESH_GAUSSIAN_C,   # use gaussian rather than mean, seems to give better results\n",
    "                                  cv2.THRESH_BINARY_INV,            # invert so foreground will be white, background will be black\n",
    "                                  11,                               # size of a pixel neighborhood used to calculate threshold value\n",
    "                                  2)                                # constant subtracted from the mean or weighted mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get separate contours from testing image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "npaContours, npaHierarchy = cv2.findContours(# input image copy since the function will modify this image in the course of finding contours\n",
    "                                             imgThresh.copy(),          \n",
    "                                             # retrieve the outermost contours only\n",
    "                                             cv2.RETR_EXTERNAL,         \n",
    "                                             # compress horizontal, vertical, and diagonal segments and leave only their end points\n",
    "                                             cv2.CHAIN_APPROX_SIMPLE)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create empty array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "allContoursWithData = []                # store all valid contours in testing image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create objects for each contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for npaContour in npaContours:          # for each contour\n",
    "    # instantiate a contour with data object\n",
    "    contourWithData = ContourWithData()\n",
    "    # assign contour to contour with data\n",
    "    contourWithData.npaContour = npaContour\n",
    "    # get the bounding rect\n",
    "    contourWithData.boundingRect = cv2.boundingRect(contourWithData.npaContour)     \n",
    "    # get bounding rect info\n",
    "    contourWithData.calculateRectTopLeftPointAndWidthAndHeight()                    \n",
    "    # calculate the contour area\n",
    "    contourWithData.fltArea = cv2.contourArea(contourWithData.npaContour)\n",
    "    # add contour with data object to list of all contours with data\n",
    "    if contourWithData.checkIfContourIsValid():\n",
    "        allContoursWithData.append(contourWithData)\n",
    "# end for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort contours from left to right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "# find maximum height of all contours\n",
    "maxHeight = max(allContoursWithData, key=lambda x: x.intRectHeight).intRectHeight\n",
    "print(maxHeight)\n",
    "# sort contours from left to right\n",
    "allContoursWithData.sort(key=lambda x: [np.ceil(x.intRectY / maxHeight), x.intRectX])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare final string, this will have the final number sequence by the end of the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "strFinalString = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F 43 51\n",
      "I 95 59\n",
      "N 156 56\n",
      "E 216 56\n",
      "A 271 59\n",
      "P 333 59\n",
      "P 385 58\n",
      "L 451 61\n",
      "F 513 54\n",
      "1 628 61\n",
      "9 686 58\n",
      "3 728 58\n",
      "6 790 55\n",
      "O 853 56\n",
      "4 903 52\n",
      "2 964 57\n",
      "Y 1079 56\n",
      "K 1139 60\n",
      "C 1186 55\n",
      "D 1247 52\n",
      "R 43 115\n",
      "A 104 118\n",
      "N 151 121\n",
      "D 209 122\n",
      "O 274 128\n",
      "M 325 124\n",
      "W 386 121\n",
      "0 447 124\n",
      "R 503 121\n",
      "D 558 121\n",
      "S 621 121\n",
      "8 681 121\n",
      "9 740 125\n",
      "2 790 124\n",
      "0 856 125\n",
      "4 914 122\n",
      "1 971 126\n",
      "7 1021 120\n",
      "9 1087 118\n",
      "3 1144 121\n",
      "X 1197 123\n",
      "Y 1261 118\n",
      "\n",
      "FINEAPPLF1936O42YKCD\n",
      "RANDOMW0RDS892041793XY\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for i in range(len(allContoursWithData)):            # for each contour\n",
    "    # draw rectangle on original testing image\n",
    "    contourWithData = allContoursWithData[i]\n",
    "    cv2.rectangle(img,                                        \n",
    "                  # upper left corner\n",
    "                  (contourWithData.intRectX, contourWithData.intRectY),\n",
    "                  (contourWithData.intRectX + contourWithData.intRectWidth,\n",
    "                   contourWithData.intRectY + contourWithData.intRectHeight),       # lower right corner\n",
    "                  (0, 255, 0),                                                      # green\n",
    "                  2)                                                                # thickness\n",
    "\n",
    "    # crop char out of threshold image\n",
    "    imgROI = imgThresh[contourWithData.intRectY: contourWithData.intRectY + contourWithData.intRectHeight,     \n",
    "                       contourWithData.intRectX: contourWithData.intRectX + contourWithData.intRectWidth]\n",
    "\n",
    "    # resize image, this will be more consistent for recognition and storage\n",
    "    imgROIResized = cv2.resize(imgROI, (RESIZED_IMAGE_WIDTH, RESIZED_IMAGE_HEIGHT))\n",
    "\n",
    "    # flatten image into 1d numpy array\n",
    "    npaROIResized = imgROIResized.reshape((1, RESIZED_IMAGE_WIDTH * RESIZED_IMAGE_HEIGHT))\n",
    "\n",
    "    # convert from 1d numpy array of ints to 1d numpy array of floats\n",
    "    npaROIResized = np.float32(npaROIResized)\n",
    "\n",
    "    # call KNN function find_nearest\n",
    "    retval, npaResults, neigh_resp, dists = kNearest.findNearest(npaROIResized, k=1)\n",
    "    \n",
    "    # get character from results\n",
    "    strCurrentChar = str(chr(int(npaResults[0][0])))\n",
    "\n",
    "    cv2.imshow(\"Test Image\", img)\n",
    "    print(strCurrentChar, contourWithData.intRectX, contourWithData.intRectY)\n",
    "\n",
    "    if cv2.waitKey(500) == 27:\n",
    "        cv2.destroyAllWindows()                         # remove windows from memory\n",
    "        cv2.waitKey(10)\n",
    "        break\n",
    "    \n",
    "    # check new line\n",
    "    if contourWithData.intRectY  > allContoursWithData[i - 1].intRectY + contourWithData.intRectHeight:\n",
    "        strFinalString += '\\n'\n",
    "    # end if\n",
    "    \n",
    "    # append current char to full string\n",
    "    strFinalString = strFinalString + strCurrentChar\n",
    "# end for\n",
    "\n",
    "print(\"\\n\" + strFinalString + \"\\n\")             # show final string\n",
    "cv2.destroyAllWindows()                         # remove windows from memory\n",
    "cv2.waitKey(10)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0537185041308504c74fc460ad6cbac8f2acb86b816e1703bfbad8fd9b716429"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('OCR-pYR5qIn7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
