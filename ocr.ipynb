{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CONTOUR_AREA = 100                      # minimum area of valid contour\n",
    "\n",
    "RESIZED_IMAGE_WIDTH = 20                    # width of resized image\n",
    "RESIZED_IMAGE_HEIGHT = 30                   # height of resized image\n",
    "\n",
    "ROWS = 5                                    # number of rows in training image\n",
    "\n",
    "TRAINING_IMAGES_PATH = 'train_images'                                       # folder with training images\n",
    "TESTING_IMAGES_PATH = 'test_images'                                         # folder with testing images\n",
    "TRAINING_ALPHA = TRAINING_IMAGES_PATH + '/' + \"train_alpha.png\"             # training alphabet image\n",
    "TRAINING_DIGIT = TRAINING_IMAGES_PATH + '/' + \"train_digit.png\"             # training digit image\n",
    "TEST_IMAGE = TESTING_IMAGES_PATH + '/' + \"test3.png\"                        # test image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define contour class to store characters in test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContourWithData():\n",
    "    npaContour = None           # contour\n",
    "    boundingRect = None         # bounding rect for contour\n",
    "    intRectX = 0                # bounding rect top left corner x location\n",
    "    intRectY = 0                # bounding rect top left corner y location\n",
    "    intRectWidth = 0            # bounding rect width\n",
    "    intRectHeight = 0           # bounding rect height\n",
    "    fltArea = 0.0               # area of contour\n",
    "\n",
    "    # calculate bounding rect info\n",
    "    def calculateRectTopLeftPointAndWidthAndHeight(self):\n",
    "        [intX, intY, intWidth, intHeight] = self.boundingRect\n",
    "        self.intRectX = intX\n",
    "        self.intRectY = intY\n",
    "        self.intRectWidth = intWidth\n",
    "        self.intRectHeight = intHeight\n",
    "\n",
    "    # this is oversimplified, for a production grade program\n",
    "    def checkIfContourIsValid(self):\n",
    "        if self.fltArea < MIN_CONTOUR_AREA:\n",
    "            return False        # much better validity checking would be necessary\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open training characters image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgTrainingAlpha = cv2.imread(TRAINING_ALPHA)               # read in training alpha image\n",
    "imgTrainingDigit = cv2.imread(TRAINING_DIGIT)            # read in training digit image\n",
    "\n",
    "if imgTrainingAlpha is None:                              # if image was not read successfully\n",
    "    # print error message to std out\n",
    "    print(\"error: alpha image not read from file \\n\\n\")\n",
    "    # and exit function (which exits program)\n",
    "    exit()\n",
    "# end if\n",
    "if imgTrainingDigit is None:                              # if image was not read successfully\n",
    "    # print error message to std out\n",
    "    print(\"error: digit image not read from file \\n\\n\")\n",
    "    # and exit function (which exits program)\n",
    "    exit()\n",
    "# end if\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify training alphabet image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgGrayAlpha = cv2.cvtColor(imgTrainingAlpha, cv2.COLOR_BGR2GRAY)                # get grayscale image\n",
    "imgBlurredAlpha = cv2.GaussianBlur(imgGrayAlpha, (5, 5), 0)                           # blur\n",
    "# filter image from grayscale to black and white\n",
    "imgThreshAlpha = cv2.adaptiveThreshold(imgBlurredAlpha,\n",
    "                                  # make pixels that pass the threshold full white\n",
    "                                  255,                                  \n",
    "                                  # use gaussian rather than mean, seems to give better results\n",
    "                                  cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                  # invert so foreground will be white, background will be black\n",
    "                                  cv2.THRESH_BINARY_INV,\n",
    "                                  # size of a pixel neighborhood used to calculate threshold value\n",
    "                                  11,\n",
    "                                  # constant subtracted from the mean or weighted mean\n",
    "                                  2)                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find seperate characters from alphabet image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npaContoursAlpha, _ = cv2.findContours(imgThreshAlpha.copy(),            # input image, make sure to use a copy since the function will modify this image in the course of finding contours\n",
    "                                       cv2.RETR_EXTERNAL,           # retrieve the outermost contours only\n",
    "                                       cv2.CHAIN_APPROX_SIMPLE)     # compress horizontal, vertical, and diagonal segments and leave only their end points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify training digit image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get grayscale image\n",
    "imgGrayDigit = cv2.cvtColor(imgTrainingDigit, cv2.COLOR_BGR2GRAY)\n",
    "imgBlurredDigit = cv2.GaussianBlur(imgGrayDigit, (5, 5), 0)                        # blur\n",
    "# filter image from grayscale to black and white\n",
    "imgThreshDigit = cv2.adaptiveThreshold(imgBlurredDigit,                           # input image\n",
    "                                  # make pixels that pass the threshold full white\n",
    "                                  255,                                  \n",
    "                                  # use gaussian rather than mean, seems to give better results\n",
    "                                  cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                  # invert so foreground will be white, background will be black\n",
    "                                  cv2.THRESH_BINARY_INV,\n",
    "                                  # size of a pixel neighborhood used to calculate threshold value\n",
    "                                  11,\n",
    "                                  # constant subtracted from the mean or weighted mean\n",
    "                                  2)                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find separate characters from digit image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npaContoursDigit, _ = cv2.findContours(imgThreshDigit.copy(),            # input image, make sure to use a copy since the function will modify this image in the course of finding contours\n",
    "                                       cv2.RETR_EXTERNAL,           # retrieve the outermost contours only\n",
    "                                       cv2.CHAIN_APPROX_SIMPLE)     # compress horizontal, vertical, and diagonal segments and leave only their end points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare empty arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AlphaContours = []\n",
    "DigitContours = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create objects for alphabet contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for npaContour in npaContoursAlpha:                              # for each contour\n",
    "    # instantiate a contour with data object\n",
    "    contourWithData = ContourWithData()\n",
    "    # assign contour to contour with data\n",
    "    contourWithData.npaContour = npaContour\n",
    "    # get the bounding rect\n",
    "    contourWithData.boundingRect = cv2.boundingRect(contourWithData.npaContour)\n",
    "    # get bounding rect info\n",
    "    contourWithData.calculateRectTopLeftPointAndWidthAndHeight()\n",
    "    # calculate the contour area\n",
    "    contourWithData.fltArea = cv2.contourArea(contourWithData.npaContour)\n",
    "    # add contour with data object to list of all contours with data\n",
    "    if contourWithData.checkIfContourIsValid():\n",
    "        AlphaContours.append(contourWithData)\n",
    "    # end if\n",
    "# end for\n",
    "\n",
    "# sort contours from left to right\n",
    "AlphaContours.sort(key = lambda x: x.intRectX)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create objects for digit contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for npaContour in npaContoursDigit:                              # for each contour\n",
    "    # instantiate a contour with data object\n",
    "    contourWithData = ContourWithData()\n",
    "    # assign contour to contour with data\n",
    "    contourWithData.npaContour = npaContour\n",
    "    # get the bounding rect\n",
    "    contourWithData.boundingRect = cv2.boundingRect(contourWithData.npaContour)\n",
    "    # get bounding rect info\n",
    "    contourWithData.calculateRectTopLeftPointAndWidthAndHeight()\n",
    "    # calculate the contour area\n",
    "    contourWithData.fltArea = cv2.contourArea(contourWithData.npaContour)\n",
    "    # add contour with data object to list of all contours with data\n",
    "    if contourWithData.checkIfContourIsValid():\n",
    "        DigitContours.append(contourWithData)\n",
    "    # end if\n",
    "# end for\n",
    "\n",
    "# sort contours from left to right\n",
    "DigitContours.sort(key=lambda x: x.intRectX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create empty arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npaFlattenedImages = np.empty((0, RESIZED_IMAGE_WIDTH * RESIZED_IMAGE_HEIGHT))\n",
    "\n",
    "# declare empty classifications list, this will be our list of how we are classifying our chars from user input, we will write to file at the end\n",
    "intClassifications = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Valid Characters which the model will detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validAlpha = [ord('A'), ord('B'), ord('C'), ord('D'), ord('E'), ord('F'), ord('G'), ord('H'), \n",
    "                ord('I'), ord('J'), ord('K'), ord('L'), ord('M'), ord('N'), ord('O'), ord('P'), ord('Q'), \n",
    "                ord('R'), ord('S'), ord('T'), ord('U'), ord('V'), ord('W'), ord('X'), ord('Y'), ord('Z')]\n",
    "\n",
    "validDigit = [ord('1'), ord('2'), ord('3'), ord('4'), ord('5'), ord('6'), ord('7'), ord('8'), ord('9'), ord('0')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label alphabet images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for npaContour in AlphaContours:                      # for each contour\n",
    "    char = validAlpha[index // ROWS]\n",
    "    # crop char out of threshold image\n",
    "    imgROI = imgThreshAlpha[npaContour.intRectY: npaContour.intRectY + npaContour.intRectHeight,\n",
    "                            npaContour.intRectX: npaContour.intRectX + npaContour.intRectWidth]\n",
    "    # resize image, this will be more consistent for recognition and storage\n",
    "    imgROIResized = cv2.resize(imgROI, (RESIZED_IMAGE_WIDTH, RESIZED_IMAGE_HEIGHT))\n",
    "    # show training numbers image\n",
    "    intClassifications.append(char)\n",
    "    # flatten image to 1d numpy array so we can write to file later\n",
    "    npaFlattenedImage = imgROIResized.reshape((1, RESIZED_IMAGE_WIDTH * RESIZED_IMAGE_HEIGHT))\n",
    "    # add current flattened impage numpy array to list of flattened image numpy arrays\n",
    "    npaFlattenedImages = np.append(npaFlattenedImages, npaFlattenedImage, 0)\n",
    "    # increment index\n",
    "    index += 1\n",
    "# end for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label digit images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for npaContour in DigitContours:                      # for each contour\n",
    "    char = validDigit[index // ROWS]\n",
    "    # crop char out of threshold image\n",
    "    imgROI = imgThreshDigit[npaContour.intRectY: npaContour.intRectY + npaContour.intRectHeight,\n",
    "                            npaContour.intRectX: npaContour.intRectX + npaContour.intRectWidth]\n",
    "    # resize image, this will be more consistent for recognition and storage\n",
    "    imgROIResized = cv2.resize(\n",
    "        imgROI, (RESIZED_IMAGE_WIDTH, RESIZED_IMAGE_HEIGHT))\n",
    "    # show training numbers image\n",
    "    intClassifications.append(char)\n",
    "    # flatten image to 1d numpy array so we can write to file later\n",
    "    npaFlattenedImage = imgROIResized.reshape(\n",
    "        (1, RESIZED_IMAGE_WIDTH * RESIZED_IMAGE_HEIGHT))\n",
    "    # add current flattened impage numpy array to list of flattened image numpy arrays\n",
    "    npaFlattenedImages = np.append(npaFlattenedImages, npaFlattenedImage, 0)\n",
    "    # increment index\n",
    "    index += 1\n",
    "# end for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fltClassifications = np.array(intClassifications, np.float32)\n",
    "\n",
    "# flatten numpy array of floats to 1d so we can write to file later\n",
    "npaClassifications = fltClassifications.reshape((fltClassifications.size, 1))\n",
    "\n",
    "print(\"\\n\\ntraining complete !!\\n\")\n",
    "\n",
    "# write flattened images to file\n",
    "np.savetxt(\"classifications.txt\", npaClassifications)\n",
    "np.savetxt(\"flattened_images.txt\", npaFlattenedImages)\n",
    "\n",
    "# remove windows from memory\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open classifications and flattened_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # read in training classifications\n",
    "    npaClassifications = np.loadtxt(\"classifications.txt\", np.float32)\n",
    "except:\n",
    "    print(\"error, unable to open classifications.txt, exiting program\\n\")\n",
    "    exit()\n",
    "# end try\n",
    "\n",
    "try:\n",
    "    # read in training images\n",
    "    npaFlattenedImages = np.loadtxt(\"flattened_images.txt\", np.float32)\n",
    "except:\n",
    "    print(\"error, unable to open flattened_images.txt, exiting program\\n\")\n",
    "    exit()\n",
    "# end try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape numpy array to 1d, necessary to pass to call to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npaClassifications = npaClassifications.reshape((npaClassifications.size, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create KNN object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNearest = cv2.ml.KNearest_create()                   # instantiate KNN object\n",
    "kNearest.train(npaFlattenedImages, cv2.ml.ROW_SAMPLE, npaClassifications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open testing image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgTestingNumbers = cv2.imread(TEST_IMAGE)           # read in testing image\n",
    "if imgTestingNumbers is None:                           # if image was not read successfully\n",
    "    print(\"error: image not read from file \\n\\n\")\n",
    "    exit()\n",
    "# end if"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get grayscale image\n",
    "imgGray = cv2.cvtColor(imgTestingNumbers, cv2.COLOR_BGR2GRAY)\n",
    "# blur image to reduce noise\n",
    "imgBlurred = cv2.GaussianBlur(imgGray, (5, 5), 0)                    \n",
    "# filter image from grayscale to black and white\n",
    "imgThresh = cv2.adaptiveThreshold(imgBlurred,                       # input image\n",
    "                                  255,                              # make pixels that pass the threshold full white\n",
    "                                  # use gaussian rather than mean, seems to give better results\n",
    "                                  cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                  # invert so foreground will be white, background will be black\n",
    "                                  cv2.THRESH_BINARY_INV,\n",
    "                                  # size of a pixel neighborhood used to calculate threshold value\n",
    "                                  11,\n",
    "                                  2)                               # constant subtracted from the mean or weighted mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get separate contours from testing image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npaContours, npaHierarchy = cv2.findContours(# input image copy since the function will modify this image in the course of finding contours\n",
    "                                             imgThresh.copy(),          \n",
    "                                             # retrieve the outermost contours only\n",
    "                                             cv2.RETR_EXTERNAL,         \n",
    "                                             # compress horizontal, vertical, and diagonal segments and leave only their end points\n",
    "                                             cv2.CHAIN_APPROX_SIMPLE)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create empty array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allContoursWithData = []                # store all valid contours in testing image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create objects for each contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for npaContour in npaContours:                             # for each contour\n",
    "    # instantiate a contour with data object\n",
    "    contourWithData = ContourWithData()\n",
    "    # assign contour to contour with data\n",
    "    contourWithData.npaContour = npaContour\n",
    "    # get the bounding rect\n",
    "    contourWithData.boundingRect = cv2.boundingRect(contourWithData.npaContour)     \n",
    "    # get bounding rect info\n",
    "    contourWithData.calculateRectTopLeftPointAndWidthAndHeight()                    \n",
    "    # calculate the contour area\n",
    "    contourWithData.fltArea = cv2.contourArea(contourWithData.npaContour)           \n",
    "    # add contour with data object to list of all contours with data\n",
    "    if contourWithData.checkIfContourIsValid():\n",
    "        allContoursWithData.append(contourWithData)\n",
    "# end for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort contours from left to right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort contours from left to right\n",
    "allContoursWithData.sort(key=lambda x: x.intRectX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare final string, this will have the final number sequence by the end of the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strFinalString = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for contourWithData in allContoursWithData:            # for each contour\n",
    "    # draw rectangle on original testing image\n",
    "    cv2.rectangle(imgTestingNumbers,                                        \n",
    "                  # upper left corner\n",
    "                  (contourWithData.intRectX, contourWithData.intRectY),\n",
    "                  (contourWithData.intRectX + contourWithData.intRectWidth,\n",
    "                   contourWithData.intRectY + contourWithData.intRectHeight),       # lower right corner\n",
    "                  (0, 255, 0),                                                      # green\n",
    "                  2)                                                                # thickness\n",
    "\n",
    "    # crop char out of threshold image\n",
    "    imgROI = imgThresh[contourWithData.intRectY: contourWithData.intRectY + contourWithData.intRectHeight,     \n",
    "                       contourWithData.intRectX: contourWithData.intRectX + contourWithData.intRectWidth]\n",
    "\n",
    "    # resize image, this will be more consistent for recognition and storage\n",
    "    imgROIResized = cv2.resize(imgROI, (RESIZED_IMAGE_WIDTH, RESIZED_IMAGE_HEIGHT))\n",
    "\n",
    "    # flatten image into 1d numpy array\n",
    "    npaROIResized = imgROIResized.reshape((1, RESIZED_IMAGE_WIDTH * RESIZED_IMAGE_HEIGHT))\n",
    "\n",
    "    # convert from 1d numpy array of ints to 1d numpy array of floats\n",
    "    npaROIResized = np.float32(npaROIResized)\n",
    "\n",
    "    # call KNN function find_nearest\n",
    "    retval, npaResults, neigh_resp, dists = kNearest.findNearest(npaROIResized, k=1)     \\\n",
    "\n",
    "    # get character from results\n",
    "    strCurrentChar = str(chr(int(npaResults[0][0])))\n",
    "\n",
    "    cv2.imshow(\"imgTestingNumbers\", imgTestingNumbers)\n",
    "    print(strCurrentChar)\n",
    "    if cv2.waitKey(0) == 27:\n",
    "        exit()\n",
    "    \n",
    "    # append current char to full string\n",
    "    strFinalString = strFinalString + strCurrentChar\n",
    "# end for\n",
    "\n",
    "print(\"\\n\" + strFinalString + \"\\n\")             # show final string\n",
    "cv2.destroyAllWindows()                         # remove windows from memory\n",
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0537185041308504c74fc460ad6cbac8f2acb86b816e1703bfbad8fd9b716429"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('OCR-pYR5qIn7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
